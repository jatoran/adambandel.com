---
title: News Aggregator
summary: Personalized, LLM‑powered news aggregation with multi‑source scraping, preference scoring, and a React UI for curation.
tags: [News, Aggregation, LLM, Microservices, Python, FastAPI, React, PostgreSQL, RSS, Reddit, Scheduler]
status: Active
date: 2025-09-29
cover_image: /project-corpus/placeholder.svg
alt: Screenshot placeholder of the News Aggregator UI with feeds, sources, filters, and curated items
permalink: /project-corpus/projects/news-aggregator/
---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>{{ page.title }} — Project</title>
    <meta name="description" content="{{ page.summary }}" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="/project-corpus/assets-styles.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a href="/project-corpus/" style="text-decoration:none;color:var(--muted)">← Back to all projects</a>
        <h1 class="project-title">{{ page.title }}</h1>
        <p class="project-subtitle">{{ page.summary }}</p>
      </div>
    </header>
    <main class="container project-main">
      <section class="project-content">
        <div class="hero">
          <img src="{{ page.cover_image }}" alt="{{ page.alt }}" />
        </div>

        <h2>Problem</h2>
        <p>
          News and social feeds produce more content than most people can reasonably review. Valuable signal is buried under sensational headlines, promotional posts, and low‑quality noise. Readers need one place to see the most relevant items across sources, with duplication reduced, facts summarized, and personalization applied to match their interests.
        </p>

        <h2>Approach</h2>
        <p>
          This project implements a modular, microservice‑based news system that ingests items from Reddit, RSS, Twitter/X, and custom websites, enriches them using LLMs, and surfaces them via a React UI. Preference rules and recommendation heuristics prioritize what matters, while filters and multiple views keep navigation fast. The design favors composability: each microservice is focused, independently deployable, and communicates over HTTP, backed by a shared Postgres database with well‑indexed JSONB fields.
        </p>

        <h3>Architecture</h3>
        <ul>
          <li>Data Fetcher (FastAPI): filter/sort/query endpoints, feeds/sources management, DB inspector.</li>
          <li>Data Ingestor (FastAPI): upserts items, processes comments, scores via preference rules, triggers web scraping + LLM.</li>
          <li>LLM Manager (FastAPI): calls OpenRouter for summaries, titles, facts, concepts, sentiment, categories; optional image descriptions.</li>
          <li>Scrapers: Reddit (asyncpraw), RSS, Twitter, and a headless web scraper for arbitrary articles.</li>
          <li>Scheduler (APScheduler): orchestrates periodic scraping per source with per‑type/user intervals; manual refresh endpoint.</li>
          <li>Logger + Service Monitor: centralized logs and standardized <code>/metrics</code> for health/capacity checks.</li>
          <li>Shared Library: SQLAlchemy models, query engine, recommendation utilities, HTTP/middleware/logging/CORS helpers.</li>
          <li>Frontend (React + Vite + MUI): feeds/sources management, advanced filters, infinite scroll lists, multiple item views, preference rules UI.</li>
        </ul>

        <h3>Stack</h3>
        <ul>
          <li>Python + FastAPI — Microservices and APIs.</li>
          <li>PostgreSQL + SQLAlchemy — Persistent store; JSONB meta fields and targeted indexes for performance.</li>
          <li>React + TypeScript + Vite + MUI — Single‑page UI with responsive layouts and theme support.</li>
          <li>asyncpraw, httpx — External fetching and concurrency.</li>
          <li>OpenRouter (LLM) — Summarization, categorization, tone/sentiment, and image description.</li>
          <li>APScheduler — Interval scheduling for scrapers and periodic stats refresh.</li>
        </ul>

        <h3>Challenges</h3>
        <ul>
          <li>Rate limits and concurrency — Bounded semaphores, retries, and staged post‑processing keep scrapers stable.</li>
          <li>Deduping and staleness (e.g., Reddit) — Upsert paths check age + metrics and skip churn while still updating engagement history.</li>
          <li>Cross‑source fatigue — Post‑processing interleaving avoids long runs from the same source/type and boosts variety.</li>
          <li>LLM cost/latency — Concurrency limits, content/engagement thresholds, and selective media analysis.</li>
          <li>Query performance — JSONB indexes, expression indexes (engagement), and a typed filter map with safe attribute resolution.</li>
        </ul>

        <h2>Outcomes</h2>
        <p>
          The system provides a unified, customizable reading experience: high‑signal items rise through preference‑based scoring, trending metrics, and an interleaved recommended order. LLM enrichment improves comprehension with neutral titles, concise summaries, key facts, and categories. Power users can tune rules and filters to shift the feed toward what they value most.
        </p>

        <h3>Notable Details</h3>
        <ul>
          <li>Query Engine — Typed operations (string/numeric/date/array/boolean), source‑specific fields (e.g., Reddit score/comments) with safe fallbacks.</li>
          <li>Recommendation Utils — Winsorized normalization and low‑engagement percentiles feed the composite “recommended” sort.</li>
          <li>Engagement History — Separate <code>EngagementMetric</code> records track time series per item and per comment.</li>
          <li>Content Items — De‑duplicates article URLs across items; web scraper fills structured title/description/content.</li>
          <li>Preferences — Per‑feed saved filters, view modes, and sidebar states; preference rules adjust item scores.</li>
        </ul>

        <section class="updates">
          <h2>Updates</h2>
          {% assign updates_base = page.url | append: 'updates/' %}
          {% assign updates = site.pages | where_exp: 'u', "u.url contains updates_base" | sort: 'date' | reverse %}
          {% if updates.size > 0 %}
            {% for u in updates limit: 5 %}
              <article class="update">
                <h3><a href="{{ u.url }}">{{ u.title }}</a></h3>
                {% if u.date %}<time datetime="{{ u.date | date_to_xmlschema }}">{{ u.date | date: '%b %d, %Y' }}</time>{% endif %}
                {% if u.excerpt %}<p>{{ u.excerpt }}</p>{% endif %}
              </article>
            {% endfor %}
          {% else %}
            <p>No updates yet.</p>
          {% endif %}
        </section>
      </section>
      <aside class="project-aside">
        <dl class="facts">
          <dt>Status</dt>
          <dd><span class="badge status {{ page.status | downcase }}">{{ page.status }}</span></dd>
          <dt>Tags</dt>
          <dd>{{ page.tags | join: ', ' }}</dd>
          <dt>Started</dt>
          <dd>{{ page.date | date: '%b %Y' }}</dd>
          <dt>Links</dt>
          <dd>
            <ul>
              <li><a href="#">Live demo</a></li>
              <li><a href="#">GitHub</a></li>
            </ul>
          </dd>
        </dl>
      </aside>
    </main>
    <footer class="site-footer">
      <div class="container">
        <small>© {{ "now" | date: "%Y" }} Adam Bandel</small>
      </div>
    </footer>
  </body>
  </html>

