---
title: LCAV — LLM Code Analysis & Validation
summary: Simulate, analyze, and safely apply LLM code changes with semantic diffs and dependency slicing.
tags: [LLM, Developer Tools, Static Analysis, FastAPI, React, Graphs, LibCST, GumTree]
status: Active
date: 2025-09-29
cover_image: /project-corpus/placeholder.svg
alt: Schematic of LCAV pipeline from LLM dump to safe apply
permalink: /project-corpus/projects/lcav/
---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>{{ page.title }} — Project</title>
    <meta name="description" content="{{ page.summary }}" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="/project-corpus/assets-styles.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a href="/project-corpus/" style="text-decoration:none;color:var(--muted)">← Back to all projects</a>
        <h1 class="project-title">{{ page.title }}</h1>
        <p class="project-subtitle">{{ page.summary }}</p>
      </div>
    </header>
    <main class="container project-main">
      <section class="project-content">
        <div class="hero">
          <img src="{{ page.cover_image }}" alt="{{ page.alt }}" />
        </div>

        <h2>Problem</h2>
        <p>
          LLMs can draft impressive multi-file changes, but safely integrating them into a real codebase is risky. Raw textual diffs miss semantics; snippets and partial patches are easy to misapply; unintended ripple effects across modules are hard to see. Teams need a repeatable way to simulate changes first, understand their impact, validate quality, and only then apply the safe subset.
        </p>

        <h2>Approach</h2>
        <p>
          LCAV is a simulation-first pipeline. It parses an LLM dump (full files, snippets, and unified diffs), matches those blocks to repository files with a multi-pass strategy, generates a <em>simulated final state</em> in memory, and analyzes that state across multiple layers before anything touches disk. Developers review textual and semantic diffs, lint results, stats, changed entities, and dependency impact slices, then selectively apply changes on a new Git branch.
        </p>

        <h3>Architecture</h3>
        <ul>
          <li>Thin client model: React UI + FastAPI backend as source of truth.</li>
          <li>Backend services: parsing, matching, simulation, diff (textual + GumTree), lint (Ruff/ESLint), stats, changed-entity detection, graph build + slicing.</li>
          <li>Simulation-first: build a <strong>Simulated Final State</strong> in memory; compare against repo state for all analysis.</li>
          <li>Structure-aware: LibCST/Jedi for Python semantics; GumTree for AST-level semantic diffs (Python/TS/JS).</li>
          <li>Dependency graphs: rustworkx PDG/SDG fragments with forward impact and backward slicing; Cytoscape visualization.</li>
          <li>Persistence: SQLModel + SQLite for project profiles and artifact cache metadata.</li>
          <li>Safety: explicit file selection, new Git branch creation, staged writes, and rollback on failure.</li>
        </ul>

        <h3>Stack</h3>
        <ul>
          <li>Backend — FastAPI, SQLModel/SQLite, LibCST, Jedi, rustworkx, GumTree CLI, Ruff, ESLint.</li>
          <li>Frontend — React (Vite), TypeScript, shadcn/ui, Tailwind, Zustand, TanStack Query, Axios.</li>
          <li>Visualization — Monaco Editor for diffs; Cytoscape.js for graphs.</li>
          <li>Parsing/Mapping — Tree-sitter for TypeScript analysis to map frontend calls to backend routes.</li>
        </ul>

        <h3>Key Capabilities</h3>
        <ul>
          <li>Robust LLM dump parser for full files, snippets, and unified diffs; new-file detection.</li>
          <li>Multi-pass matching cascade: overrides → exact → fuzzy → diff headers → content similarity.</li>
          <li>Textual and semantic diffs, plus function/class entity detection (Python) across original vs. simulated content.</li>
          <li>Program graphing: per-file PDG/SDG fragments with forward impact analysis and on-demand backward slicing.</li>
          <li>API call mapping: scan TS/TSX to connect frontend API wrappers to FastAPI endpoints.</li>
          <li>Safe apply: branch creation, selected-file writes, staged commit, and error-aware rollback.</li>
        </ul>

        <h3>Challenges</h3>
        <ul>
          <li>LLM output variability — Solved with a tolerant block parser and a layered matching strategy with explicit user overrides.</li>
          <li>Patch reliability — Unified diffs are applied in sequence with error capture; snippets/full-files override diffs deterministically.</li>
          <li>Python’s dynamism — Graphs favor pragmatic precision, highlighting uncertainty and focusing on common patterns first.</li>
          <li>Performance & scale — Content-hash caching, file-scoped graphs, and demand-driven slicing keep interactions responsive.</li>
          <li>Cross-file semantics — Jedi-backed resolution and import/call edges establish a foundation for inter-file impact.</li>
        </ul>

        <h2>Outcomes</h2>
        <p>
          LCAV delivers an end-to-end review and apply workflow: from a pasted LLM response to simulated state, diffs and linting, dependency impact visualization, and finally a controlled Git apply of only the vetted files. The result is higher confidence, clearer understanding, and safer adoption of AI-assisted changes in real repositories.
        </p>

        <section class="updates">
          <h2>Updates</h2>
          {% assign updates_base = page.url | append: 'updates/' %}
          {% assign updates = site.pages | where_exp: 'u', "u.url contains updates_base" | sort: 'date' | reverse %}
          {% if updates.size > 0 %}
            {% for u in updates limit: 5 %}
              <article class="update">
                <h3><a href="{{ u.url }}">{{ u.title }}</a></h3>
                {% if u.date %}<time datetime="{{ u.date | date_to_xmlschema }}">{{ u.date | date: '%b %d, %Y' }}</time>{% endif %}
                {% if u.excerpt %}<p>{{ u.excerpt }}</p>{% endif %}
              </article>
            {% endfor %}
          {% else %}
            <p>No updates yet.</p>
          {% endif %}
        </section>
      </section>
      <aside class="project-aside">
        <dl class="facts">
          <dt>Status</dt>
          <dd><span class="badge status {{ page.status | downcase }}">{{ page.status }}</span></dd>
          <dt>Tags</dt>
          <dd>{{ page.tags | join: ', ' }}</dd>
          <dt>Started</dt>
          <dd>{{ page.date | date: '%b %Y' }}</dd>
          <dt>Links</dt>
          <dd>
            <ul>
              <li><a href="#">Live demo (TBD)</a></li>
              <li><a href="#">GitHub (TBD)</a></li>
            </ul>
          </dd>
        </dl>
      </aside>
    </main>
    <footer class="site-footer">
      <div class="container">
        <small>© {{ "now" | date: "%Y" }} Adam Bandel</small>
      </div>
    </footer>
  </body>
  </html>

